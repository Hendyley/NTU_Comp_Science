{"cells":[{"cell_type":"code","execution_count":null,"id":"c8c630ad","metadata":{"id":"c8c630ad"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"id":"e54b33d1","metadata":{"id":"e54b33d1","outputId":"92e79667-0ab9-4177-9ed6-38597f1a9c3c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730899858067,"user_tz":-480,"elapsed":6751,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"]}],"source":["!pip install datasets"]},{"cell_type":"markdown","id":"a3a78089","metadata":{"id":"a3a78089"},"source":["## Part 1"]},{"cell_type":"code","execution_count":4,"id":"98bbf012","metadata":{"id":"98bbf012","outputId":"8cbdd763-1e6f-4802-c9a6-07a9bd69a31e","colab":{"base_uri":"https://localhost:8080/","height":417,"referenced_widgets":["1eaeafc739b7429885bc067a1338f93b","d459ef8602ca45259d414c800b1555dd","9d3dd33a67ca45a9992501ba088c5f2c","83bf335d998e403d9416bb000eecb08d","97af5cde7c034fe1b976e709c9d77415","233d0f97b7cb466f85d7da7236d23e3c","8bf28eaafe9b4ec6ba24096dad298460","a5f045f9150a44a88ef41bacb39b7022","03741984e10d458599849597a5c6c713","9acadcd18490400dbbb8cee530f81131","e72fe962d53546619c6d5499dbd260a2","3e094a560a3f4f5aa9d51d14d2de60de","3fe110ea8bae433b95a74281aa80058a","db19ec725a70457c8fc81f92f54ab549","9c7e712053794112ace3cc5033ab7e22","f48c5a035ec64ff98e77561c783f6982","2d545a628e3d4834878dc719f547d666","bcfcaeba5cb040ccb655d93935b21542","e79ae022570443ea97fcf4fdf9a69ae9","7917a1a3bf53496d9f2862162ef1c511","2d6ac49983264c00a59a71e84aaee965","e4296c8b138f4b6e94f04787d39cc42d","d43cbc3e48c54a288c15f984fabc1295","09aa48a3099f4cdf88ac47fabb34b8e0","2a749993df8f462091b9fd000c9049ce","8e8665f721f747b2917063383d47e6d2","507204dca10f40efaeb9802cc528164f","95cd4944dce04ea993ffa5a7aa9d9a77","872589abab474180b267b247e498ef6c","96a4d35b79d04146be9f8f702b6e65c4","0064eeebb72a45408027b4989764d47d","94c74f7de1c84b918b0b5c8fed7cb78f","a3d55ae533774c20a63fc3c0f9849d5a","ce3d6b84fd3244ec8b4dc3b0f4377b42","95fffec6311c41dbbc806b114d39f3d8","ddcb0987684b43ca91d0b0ebb1195a4c","fb91f09d1dd547018840305cce8584e2","58b9161328334eed8042e683836f268b","a23d18936ea04674988d9a594a9793fb","6a350b91b09f400a91d8f0d8406440d1","66d31298737b45a8856e8d2194d3b017","2fbc36cbc4e74637b6b9f936906174d5","8498a5e31138441ba348e9a8b2357bf7","f71e78769e0c413fb867f2306684d59a","4a8c37a79a1043168031b89b9d611885","4ad697d17c78491682ecab0d549e1c5f","887e8addc0f24123972169a728fe4a01","830699661bce4d378b9b68e758031c6e","ba28137209384d249a5ad65ece0c4fc7","a057581b593c4fff959ed6ba0a3deb61","9ec75cba7f5c4eeca23f05ff1e5a7924","fe7a008d71dd4936b1d5488d1ba6c32f","78d5eb3bfb534f3f9258c15fcba80065","0616160454fd4fa9ac1425b4b6c4dddd","9b887a6f1b6046cf8efa6cdf4ab5b69c","719942d754a941faa7084206457746ce","676d434e8b4646e295aec532c5ec5afa","e6a35a17cea142419e1355f3fd396f3a","9070cc2b799547aab8a164a1ee46c610","993153cf320c41dda456162f7082d65d","8ea7bd52d2c346bcbe8bdb3069cd6549","1d5ac23553b0460b931a8f8f38eaf279","84cc52be0a4448d6a81fd7c658a7e07c","403ca25848674f51b057c80b27d19cdb","d946086111f24172b5b39ba2429f12e3","f528d805680d43fb84c3b69c413495b0","788e221ffa644efe81418aec13c3e2b5","362a6994dad74285a66fd27715b87eed","55c2791b76584f7c958b4eef0e6311ac","01cade4a2c5c4443a9c258d6c56c6902","bf5be7fdaa75481691c14f81b64360d3","089155ac8f244c6fb099531e72725446","337fb731ff2649058504d1ed3d28b948","67de08048f8540f0aece6fb0f4909927","aa7bc58b61584cc691a4391ab5bd0bc3","5a9296c6303f4bf5a474c459569f7acb","b2b210a445714b8793e4657d7463ef7a"]},"executionInfo":{"status":"ok","timestamp":1730899885721,"user_tz":-480,"elapsed":24544,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/7.46k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eaeafc739b7429885bc067a1338f93b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["train.parquet:   0%|          | 0.00/699k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e094a560a3f4f5aa9d51d14d2de60de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["validation.parquet:   0%|          | 0.00/90.0k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d43cbc3e48c54a288c15f984fabc1295"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["test.parquet:   0%|          | 0.00/92.2k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce3d6b84fd3244ec8b4dc3b0f4377b42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/8530 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8c37a79a1043168031b89b9d611885"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating validation split:   0%|          | 0/1066 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"719942d754a941faa7084206457746ce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating test split:   0%|          | 0/1066 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"788e221ffa644efe81418aec13c3e2b5"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["The size of the vocabulary is: 18029\n"]}],"source":["# Question 1(a): What is the size of the vocabulary formed from your training data?\n","\n","from datasets import load_dataset\n","import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","\n","# Load the dataset\n","dataset = load_dataset(\"rotten_tomatoes\")\n","train_dataset = dataset['train']\n","\n","# Initialize an empty set to store unique words\n","vocabulary = set()\n","\n","# Tokenize each review in the training dataset and update the vocabulary set\n","for text in train_dataset['text']:\n","    tokens = word_tokenize(text.lower())\n","    vocabulary.update(tokens)\n","\n","# Print the size of the vocabulary\n","print(\"The size of the vocabulary is:\", len(vocabulary))"]},{"cell_type":"code","execution_count":null,"id":"b3f3bedd","metadata":{"id":"b3f3bedd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":10,"id":"edb13d4a","metadata":{"id":"edb13d4a","outputId":"51df4864-eaa1-4f8f-f9c2-429b317ac62a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730900566935,"user_tz":-480,"elapsed":3773,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of OOV words in the training data: 1865\n"]}],"source":["# Question 1(b): How many OOV words exist in your training data?\n","\n","import numpy as np\n","\n","# Load the GloVe embeddings (make sure to download 'glove.6B.100d.txt' and place it in the working directory)\n","glove_vocab = set()\n","with open('glove.6B.100d.txt', 'r', encoding='utf8') as f:\n","    for line in f:\n","        word = line.split()[0]\n","        glove_vocab.add(word)\n","\n","# Identify OOV words\n","oov_words = vocabulary - glove_vocab\n","\n","# Print the number of OOV words\n","print(\"Number of OOV words in the training data:\", len(oov_words))"]},{"cell_type":"code","execution_count":null,"id":"8b92c546","metadata":{"id":"8b92c546"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":11,"id":"50688a71","metadata":{"id":"50688a71","outputId":"be3890b3-6b18-4162-ea44-2b9e91287489","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730900576000,"user_tz":-480,"elapsed":5133,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Embedding matrix shape: (18029, 100)\n"]}],"source":["# Question 1(c): Mitigating OOV Words by Initializing Random Embeddings\n","\n","embedding_dim = 100  # Dimensionality of GloVe embeddings\n","import numpy as np\n","\n","# Create mappings between words and indices\n","word2idx = {}\n","idx2word = {}\n","for idx, word in enumerate(vocabulary):\n","    word2idx[word] = idx\n","    idx2word[idx] = word\n","\n","# Initialize the embedding matrix with random values\n","embedding_matrix = np.random.uniform(-0.05, 0.05, (len(vocabulary), embedding_dim))\n","\n","# Load GloVe embeddings into the embedding matrix where possible\n","with open('glove.6B.100d.txt', 'r', encoding='utf8') as f:\n","    for line in f:\n","        values = line.split()\n","        glove_word = values[0]\n","        if glove_word in word2idx:\n","            vector = np.asarray(values[1:], dtype='float32')\n","            idx = word2idx[glove_word]\n","            embedding_matrix[idx] = vector\n","\n","# Now, embedding_matrix contains GloVe embeddings for known words and random values for OOV words\n","print(\"Embedding matrix shape:\", embedding_matrix.shape)"]},{"cell_type":"markdown","id":"c8eba559","metadata":{"id":"c8eba559"},"source":["## Part 2"]},{"cell_type":"code","execution_count":12,"metadata":{"outputId":"14fab8d2-a1a2-436d-fffe-4ad475a16440","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730900603716,"user_tz":-480,"elapsed":27718,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}},"id":"NEz9pKk9W-Ho"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["# Import necessary libraries\n","from datasets import load_dataset\n","import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt')\n","import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn as nn\n","\n","# Load the dataset\n","dataset = load_dataset(\"rotten_tomatoes\")\n","train_raw = dataset['train']\n","validation_raw = dataset['validation']\n","test_raw = dataset['test']\n","\n","# Build the vocabulary from training data\n","vocabulary = set()\n","for text in train_raw['text']:\n","    tokens = word_tokenize(text.lower())\n","    vocabulary.update(tokens)\n","\n","# Add special tokens\n","vocabulary.add('<unk>')\n","vocabulary.add('<pad>')\n","\n","# Create mappings between words and indices\n","word2idx = {word: idx for idx, word in enumerate(vocabulary)}\n","idx2word = {idx: word for word, idx in word2idx.items()}\n","\n","# Initialize the embedding matrix\n","embedding_dim = 100  # Dimensionality of GloVe embeddings\n","vocab_size = len(word2idx)\n","embedding_matrix = np.random.uniform(-0.05, 0.05, (vocab_size, embedding_dim))\n","\n","# Load GloVe embeddings (ensure 'glove.6B.100d.txt' is in your working directory)\n","glove_path = 'glove.6B.100d.txt'  # Update the path if necessary\n","with open(glove_path, 'r', encoding='utf8') as f:\n","    for line in f:\n","        values = line.strip().split()\n","        if len(values) == embedding_dim + 1:\n","            word = values[0]\n","            vector = np.asarray(values[1:], dtype='float32')\n","            if word in word2idx:\n","                idx = word2idx[word]\n","                embedding_matrix[idx] = vector\n","\n","# Set the embedding for '<pad>' token to zeros\n","pad_idx = word2idx['<pad>']\n","embedding_matrix[pad_idx] = np.zeros(embedding_dim)\n","\n","# Define a function to convert sentences to indices\n","def sentence_to_indices(sentence, word2idx):\n","    tokens = word_tokenize(sentence.lower())\n","    indices = []\n","    for token in tokens:\n","        if token in word2idx:\n","            indices.append(word2idx[token])\n","        else:\n","            indices.append(word2idx['<unk>'])  # Map unknown words to '<unk>'\n","    return indices\n","\n","# Define the custom Dataset class\n","class SentimentDataset(Dataset):\n","    def __init__(self, texts, labels, word2idx):\n","        self.texts = texts\n","        self.labels = labels\n","        self.word2idx = word2idx\n","\n","    def __len__(self):\n","        return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","        indices = sentence_to_indices(text, self.word2idx)\n","        return torch.tensor(indices, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n","\n","# Create datasets for training, validation, and testing\n","train_dataset = SentimentDataset(train_raw['text'], train_raw['label'], word2idx)\n","val_dataset = SentimentDataset(validation_raw['text'], validation_raw['label'], word2idx)\n","test_dataset = SentimentDataset(test_raw['text'], test_raw['label'], word2idx)\n","\n","# Define the collate_fn function for padding within batches\n","def collate_fn(batch):\n","    sequences = [item[0] for item in batch]\n","    labels = torch.tensor([item[1] for item in batch], dtype=torch.float)\n","    sequences_padded = pad_sequence(sequences, batch_first=True, padding_value=word2idx['<pad>'])\n","    return sequences_padded, labels\n","\n","# Create DataLoaders for training, validation, and testing\n","batch_size = 64\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)"],"id":"NEz9pKk9W-Ho"},{"cell_type":"markdown","source":["Max Pooling"],"metadata":{"id":"eJsE_pX8QF-W"},"id":"eJsE_pX8QF-W"},{"cell_type":"code","execution_count":13,"id":"bff4efb2","metadata":{"id":"bff4efb2","outputId":"4c641fce-d06f-4309-fd36-b3888ea86282","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730869697050,"user_tz":-480,"elapsed":2679656,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/30], Loss: 0.6267, Validation Accuracy: 0.6698\n","Epoch [2/30], Loss: 0.5237, Validation Accuracy: 0.7514\n","Epoch [3/30], Loss: 0.4834, Validation Accuracy: 0.7617\n","Epoch [4/30], Loss: 0.4584, Validation Accuracy: 0.7683\n","Epoch [5/30], Loss: 0.4383, Validation Accuracy: 0.7664\n","Epoch [6/30], Loss: 0.4143, Validation Accuracy: 0.7645\n","Epoch [7/30], Loss: 0.3880, Validation Accuracy: 0.7683\n","Epoch [8/30], Loss: 0.3369, Validation Accuracy: 0.7692\n","Epoch [9/30], Loss: 0.3103, Validation Accuracy: 0.7749\n","Epoch [10/30], Loss: 0.2886, Validation Accuracy: 0.7645\n","Epoch [11/30], Loss: 0.2616, Validation Accuracy: 0.7730\n","Epoch [12/30], Loss: 0.2403, Validation Accuracy: 0.7786\n","Epoch [13/30], Loss: 0.2163, Validation Accuracy: 0.7674\n","Epoch [14/30], Loss: 0.1843, Validation Accuracy: 0.7617\n","Epoch [15/30], Loss: 0.1675, Validation Accuracy: 0.7580\n","Epoch [16/30], Loss: 0.1307, Validation Accuracy: 0.7598\n","Epoch [17/30], Loss: 0.1061, Validation Accuracy: 0.7561\n","Early stopping!\n"]}],"source":["# Define the RNN model using pre-trained embeddings\n","class SentimentRNNWithMaxPool(nn.Module):\n","    def __init__(self, embedding_matrix):\n","        super(SentimentRNNWithMaxPool, self).__init__()\n","        vocab_size, embedding_dim = embedding_matrix.shape\n","        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32), freeze=True)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size=256, batch_first=True, bidirectional=True, num_layers=2, dropout=0.5)\n","        self.fc1 = nn.Linear(512, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        embeds = self.embedding(x)\n","        lstm_out, (h_n, c_n) = self.lstm(embeds)\n","\n","        # Concatenate the final hidden states from both directions\n","        # out = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n","\n","        # Max-Pooling\n","        out, _ = torch.max(lstm_out, dim=1)\n","\n","        out = self.dropout(out)\n","        out = self.relu(self.fc1(out))\n","        out = self.dropout(out)\n","        out = torch.sigmoid(self.fc2(out))\n","        return out.squeeze()\n","\n","\n","# Instantiate the model\n","model = SentimentRNNWithMaxPool(embedding_matrix)\n","\n","# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.5, verbose=True)\n","\n","# Training loop with validation and early stopping\n","num_epochs = 30\n","patience = 5  # Early stopping patience\n","best_val_accuracy = 0\n","epochs_no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for sequences, labels in train_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(sequences)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)  # Gradient clipping\n","        optimizer.step()\n","        running_loss += loss.item() * sequences.size(0)\n","    epoch_loss = running_loss / len(train_dataset)\n","\n","    # Validation\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for sequences, labels in val_loader:\n","            sequences = sequences.to(device)\n","            labels = labels.to(device)\n","            outputs = model(sequences)\n","            predicted = (outputs >= 0.5).long()\n","            correct += (predicted == labels.long()).sum().item()\n","            total += labels.size(0)\n","    val_accuracy = correct / total\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # Learning rate scheduling\n","    scheduler.step(val_accuracy)\n","\n","    # Check for improvement\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        epochs_no_improve = 0\n","        # Save the best model\n","        torch.save(model.state_dict(), 'best_model_max_pooling.pt')\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print('Early stopping!')\n","            break"]},{"cell_type":"code","source":["# Load the best model and evaluate on the test set\n","model = SentimentRNNWithMaxPool(embedding_matrix)\n","model.load_state_dict(torch.load('best_model_max_pooling.pt'))\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for sequences, labels in test_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        outputs = model(sequences)\n","        predicted = (outputs >= 0.5).long()\n","        correct += (predicted == labels.long()).sum().item()\n","        total += labels.size(0)\n","test_accuracy = correct / total\n","print(f'Accuracy Score on Test dataset: {test_accuracy:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ncGN1rrtqJw","executionInfo":{"status":"ok","timestamp":1730899001769,"user_tz":-480,"elapsed":8617,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}},"outputId":"b079b9fa-d26e-4d43-9f27-1117227dfa73"},"id":"4ncGN1rrtqJw","execution_count":50,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-50-db978e38f2f4>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('best_model_max_pooling.pt'))\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy Score on Test dataset: 0.7730\n"]}]},{"cell_type":"markdown","source":["Average Pooling"],"metadata":{"id":"ThhJgb9OP6z0"},"id":"ThhJgb9OP6z0"},{"cell_type":"code","execution_count":15,"metadata":{"outputId":"636159a6-4c44-4da7-aee2-b2aa0459235f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730872580078,"user_tz":-480,"elapsed":2533399,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}},"id":"DXL_DL6EEJWi"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/30], Loss: 0.6542, Validation Accuracy: 0.6717\n","Epoch [2/30], Loss: 0.5560, Validation Accuracy: 0.7420\n","Epoch [3/30], Loss: 0.5167, Validation Accuracy: 0.7439\n","Epoch [4/30], Loss: 0.4937, Validation Accuracy: 0.7617\n","Epoch [5/30], Loss: 0.4653, Validation Accuracy: 0.7514\n","Epoch [6/30], Loss: 0.4531, Validation Accuracy: 0.7692\n","Epoch [7/30], Loss: 0.4226, Validation Accuracy: 0.7617\n","Epoch [8/30], Loss: 0.4003, Validation Accuracy: 0.7777\n","Epoch [9/30], Loss: 0.3777, Validation Accuracy: 0.7617\n","Epoch [10/30], Loss: 0.3536, Validation Accuracy: 0.7749\n","Epoch [11/30], Loss: 0.3266, Validation Accuracy: 0.7880\n","Epoch [12/30], Loss: 0.2864, Validation Accuracy: 0.7533\n","Epoch [13/30], Loss: 0.2532, Validation Accuracy: 0.7542\n","Epoch [14/30], Loss: 0.2202, Validation Accuracy: 0.7767\n","Epoch [15/30], Loss: 0.1489, Validation Accuracy: 0.7758\n","Epoch [16/30], Loss: 0.1168, Validation Accuracy: 0.7795\n","Early stopping!\n"]}],"source":["# Define the RNN model using pre-trained embeddings\n","class SentimentRNNWithAvgPool(nn.Module):\n","    def __init__(self, embedding_matrix):\n","        super(SentimentRNNWithAvgPool, self).__init__()\n","        vocab_size, embedding_dim = embedding_matrix.shape\n","        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32), freeze=True)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size=256, batch_first=True, bidirectional=True, num_layers=2, dropout=0.5)\n","        self.fc1 = nn.Linear(512, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        embeds = self.embedding(x)\n","        lstm_out, (h_n, c_n) = self.lstm(embeds)\n","\n","        # Concatenate the final hidden states from both directions\n","        # out = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n","\n","        # Average-Pooling\n","        out = torch.mean(lstm_out, dim=1)\n","\n","        out = self.dropout(out)\n","        out = self.relu(self.fc1(out))\n","        out = self.dropout(out)\n","        out = torch.sigmoid(self.fc2(out))\n","        return out.squeeze()\n","\n","\n","# Instantiate the model\n","model = SentimentRNNWithAvgPool(embedding_matrix)\n","\n","# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.5, verbose=True)\n","\n","# Training loop with validation and early stopping\n","num_epochs = 30\n","patience = 5  # Early stopping patience\n","best_val_accuracy = 0\n","epochs_no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for sequences, labels in train_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(sequences)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)  # Gradient clipping\n","        optimizer.step()\n","        running_loss += loss.item() * sequences.size(0)\n","    epoch_loss = running_loss / len(train_dataset)\n","\n","    # Validation\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for sequences, labels in val_loader:\n","            sequences = sequences.to(device)\n","            labels = labels.to(device)\n","            outputs = model(sequences)\n","            predicted = (outputs >= 0.5).long()\n","            correct += (predicted == labels.long()).sum().item()\n","            total += labels.size(0)\n","    val_accuracy = correct / total\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # Learning rate scheduling\n","    scheduler.step(val_accuracy)\n","\n","    # Check for improvement\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        epochs_no_improve = 0\n","        # Save the best model\n","        torch.save(model.state_dict(), 'best_model_avg_pooling.pt')\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print('Early stopping!')\n","            break\n"],"id":"DXL_DL6EEJWi"},{"cell_type":"code","source":["# Load the best model and evaluate on the test set\n","model = SentimentRNNWithAvgPool(embedding_matrix)\n","model.load_state_dict(torch.load('best_model_avg_pooling.pt'))\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for sequences, labels in test_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        outputs = model(sequences)\n","        predicted = (outputs >= 0.5).long()\n","        correct += (predicted == labels.long()).sum().item()\n","        total += labels.size(0)\n","test_accuracy = correct / total\n","print(f'Accuracy Score on Test dataset: {test_accuracy:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Q7exrrDsfPa","executionInfo":{"status":"ok","timestamp":1730899007119,"user_tz":-480,"elapsed":5354,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}},"outputId":"68eb801f-6c24-434d-b26b-b6232e510860"},"id":"4Q7exrrDsfPa","execution_count":51,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-51-006036b188b5>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('best_model_avg_pooling.pt'))\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy Score on Test dataset: 0.7927\n"]}]},{"cell_type":"markdown","source":["Simple Attention Mechanism"],"metadata":{"id":"wscXnvbLP1_-"},"id":"wscXnvbLP1_-"},{"cell_type":"code","execution_count":25,"metadata":{"outputId":"858de6e2-58f8-47fb-b65c-c7c1f159325c","colab":{"base_uri":"https://localhost:8080/"},"id":"GSY1FuiPPypM","executionInfo":{"status":"ok","timestamp":1730907820442,"user_tz":-480,"elapsed":2797131,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/30], Loss: 0.6519, Validation Accuracy: 0.6332\n","Epoch [2/30], Loss: 0.5405, Validation Accuracy: 0.7495\n","Epoch [3/30], Loss: 0.4987, Validation Accuracy: 0.7514\n","Epoch [4/30], Loss: 0.4682, Validation Accuracy: 0.7627\n","Epoch [5/30], Loss: 0.4439, Validation Accuracy: 0.7627\n","Epoch [6/30], Loss: 0.4263, Validation Accuracy: 0.7514\n","Epoch [7/30], Loss: 0.4061, Validation Accuracy: 0.7580\n","Epoch [8/30], Loss: 0.3572, Validation Accuracy: 0.7852\n","Epoch [9/30], Loss: 0.3296, Validation Accuracy: 0.7598\n","Epoch [10/30], Loss: 0.2967, Validation Accuracy: 0.7692\n","Epoch [11/30], Loss: 0.2785, Validation Accuracy: 0.7533\n","Epoch [12/30], Loss: 0.2279, Validation Accuracy: 0.7711\n","Epoch [13/30], Loss: 0.2074, Validation Accuracy: 0.7655\n","Early stopping!\n"]}],"source":["class SimpleAttention(nn.Module):\n","  def __init__(self, hidden_size):\n","      super(SimpleAttention, self).__init__()\n","      self.weight = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n","      self.bias = nn.Parameter(torch.Tensor(hidden_size))\n","\n","  def forward(self, hidden_states):\n","      # hidden_states: [batch_size, seq_len, hidden_size]\n","      batch_size, seq_len, hidden_size = hidden_states.size()\n","\n","      # Calculate attention weights\n","      weights = torch.bmm(hidden_states, self.weight.unsqueeze(0).repeat(batch_size, 1, 1))\n","      weights = torch.tanh(weights + self.bias.unsqueeze(0).unsqueeze(1).repeat(batch_size, seq_len, 1))\n","      weights = torch.softmax(weights, dim=1)  # Normalize weights\n","\n","      # Weight the hidden states\n","      weighted_hidden_states = hidden_states * weights\n","\n","      # Aggregate the weighted hidden states\n","      context_vector = torch.sum(weighted_hidden_states, dim=1)  # Sum across time steps\n","\n","      return context_vector\n","\n","\n","# Define the RNN model using pre-trained embeddings\n","class SentimentRNNWithSimpleAttention(nn.Module):\n","    def __init__(self, embedding_matrix):\n","        super(SentimentRNNWithSimpleAttention, self).__init__()\n","        vocab_size, embedding_dim = embedding_matrix.shape\n","        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32), freeze=True)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size=256, batch_first=True, bidirectional=True, num_layers=2, dropout=0.5)\n","        self.fc1 = nn.Linear(512, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","        self.attention = SimpleAttention(hidden_size=512)\n","\n","    def forward(self, x):\n","        embeds = self.embedding(x)\n","        lstm_out, (h_n, c_n) = self.lstm(embeds)\n","\n","        # Apply Attention Mechanism\n","        context_vector = self.attention(lstm_out)\n","\n","        context_vector = self.dropout(context_vector)\n","        context_vector = self.relu(self.fc1(context_vector))\n","        context_vector = self.dropout(context_vector)\n","        context_vector = torch.sigmoid(self.fc2(context_vector))\n","        return context_vector.squeeze()\n","\n","\n","# Instantiate the model\n","model = SentimentRNNWithSimpleAttention(embedding_matrix)\n","\n","# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.5, verbose=True)\n","\n","# Training loop with validation and early stopping\n","num_epochs = 30\n","patience = 5  # Early stopping patience\n","best_val_accuracy = 0\n","epochs_no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for sequences, labels in train_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(sequences)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)  # Gradient clipping\n","        optimizer.step()\n","        running_loss += loss.item() * sequences.size(0)\n","    epoch_loss = running_loss / len(train_dataset)\n","\n","    # Validation\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for sequences, labels in val_loader:\n","            sequences = sequences.to(device)\n","            labels = labels.to(device)\n","            outputs = model(sequences)\n","            predicted = (outputs >= 0.5).long()\n","            correct += (predicted == labels.long()).sum().item()\n","            total += labels.size(0)\n","    val_accuracy = correct / total\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # Learning rate scheduling\n","    scheduler.step(val_accuracy)\n","\n","    # Check for improvement\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        epochs_no_improve = 0\n","        # Save the best model\n","        torch.save(model.state_dict(), 'best_model_simple_attention.pt')\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print('Early stopping!')\n","            break"],"id":"GSY1FuiPPypM"},{"cell_type":"code","source":["# Load the best model and evaluate on the test set\n","model = SentimentRNNWithSimpleAttention(embedding_matrix)\n","model.load_state_dict(torch.load('best_model_simple_attention.pt'))\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for sequences, labels in test_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        outputs = model(sequences)\n","        predicted = (outputs >= 0.5).long()\n","        correct += (predicted == labels.long()).sum().item()\n","        total += labels.size(0)\n","test_accuracy = correct / total\n","print(f'Accuracy Score on Test dataset: {test_accuracy:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U_oaftgqsjyu","executionInfo":{"status":"ok","timestamp":1730908376818,"user_tz":-480,"elapsed":8577,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}},"outputId":"ae4e4e77-0318-4a38-bbf2-e2f561459866"},"id":"U_oaftgqsjyu","execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-26-716fc89b4886>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('best_model_simple_attention.pt'))\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy Score on Test dataset: 0.7899\n"]}]},{"cell_type":"markdown","source":["Self-Attention Mechanism"],"metadata":{"id":"jOwHtqrkMBFr"},"id":"jOwHtqrkMBFr"},{"cell_type":"code","execution_count":13,"metadata":{"outputId":"8b6af302-84f1-477d-9bfb-d37f1e19b6e4","colab":{"base_uri":"https://localhost:8080/"},"id":"k3rsRF-XMDh6","executionInfo":{"status":"ok","timestamp":1730903280107,"user_tz":-480,"elapsed":2676394,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/30], Loss: 0.6259, Validation Accuracy: 0.7223\n","Epoch [2/30], Loss: 0.5348, Validation Accuracy: 0.7373\n","Epoch [3/30], Loss: 0.4940, Validation Accuracy: 0.7533\n","Epoch [4/30], Loss: 0.4661, Validation Accuracy: 0.7570\n","Epoch [5/30], Loss: 0.4539, Validation Accuracy: 0.7767\n","Epoch [6/30], Loss: 0.4307, Validation Accuracy: 0.7486\n","Epoch [7/30], Loss: 0.4088, Validation Accuracy: 0.7655\n","Epoch [8/30], Loss: 0.3816, Validation Accuracy: 0.7711\n","Epoch [9/30], Loss: 0.3324, Validation Accuracy: 0.7720\n","Epoch [10/30], Loss: 0.3011, Validation Accuracy: 0.7767\n","Early stopping!\n"]}],"source":["class SelfAttention(nn.Module):\n","  def __init__(self, hidden_size):\n","      super(SelfAttention, self).__init__()\n","      self.query = nn.Linear(hidden_size, hidden_size)  # Linear layer for query\n","      self.key = nn.Linear(hidden_size, hidden_size)    # Linear layer for key\n","      self.value = nn.Linear(hidden_size, hidden_size)  # Linear layer for value\n","\n","  def forward(self, hidden_states):\n","      # hidden_states: [batch_size, seq_len, hidden_size]\n","      batch_size, seq_len, hidden_size = hidden_states.size()\n","\n","      # Calculate vectors\n","      Q = self.query(hidden_states)\n","      K = self.key(hidden_states)\n","      V = self.value(hidden_states)\n","\n","      # Calculate attention weights\n","      attention_weights = torch.bmm(Q, K.transpose(1, 2)) / (hidden_size ** 0.5)\n","      attention_weights = torch.softmax(attention_weights, dim=-1)\n","\n","      # Weight the value vectors by attention weights\n","      weighted_values = torch.bmm(attention_weights, V)\n","\n","      return weighted_values\n","\n","class SimpleAttention(nn.Module):\n","  def __init__(self, hidden_size):\n","      super(SimpleAttention, self).__init__()\n","      self.weight = nn.Parameter(torch.Tensor(hidden_size, hidden_size))\n","      self.bias = nn.Parameter(torch.Tensor(hidden_size))\n","\n","  def forward(self, hidden_states):\n","      # hidden_states: [batch_size, seq_len, hidden_size]\n","      batch_size, seq_len, hidden_size = hidden_states.size()\n","\n","      # Calculate attention weights\n","      weights = torch.bmm(hidden_states, self.weight.unsqueeze(0).repeat(batch_size, 1, 1))\n","      weights = torch.tanh(weights + self.bias.unsqueeze(0).unsqueeze(1).repeat(batch_size, seq_len, 1))\n","      weights = torch.softmax(weights, dim=1)  # Normalize weights\n","\n","      # Weight the hidden states\n","      weighted_hidden_states = hidden_states * weights\n","\n","      # Aggregate the weighted hidden states\n","      context_vector = torch.sum(weighted_hidden_states, dim=1)  # Sum across time steps\n","\n","      return context_vector\n","\n","\n","# Define the RNN model using pre-trained embeddings\n","class SentimentRNNWithSelfAttention(nn.Module):\n","    def __init__(self, embedding_matrix):\n","        super(SentimentRNNWithSelfAttention, self).__init__()\n","        vocab_size, embedding_dim = embedding_matrix.shape\n","        self.embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix, dtype=torch.float32), freeze=True)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size=256, batch_first=True, bidirectional=True, num_layers=2, dropout=0.5)\n","        self.fc1 = nn.Linear(512, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","        self.self_attention = SelfAttention(hidden_size=512)\n","        self.simple_attention = SimpleAttention(hidden_size=512)\n","\n","    def forward(self, x):\n","        embeds = self.embedding(x)\n","        lstm_out, (h_n, c_n) = self.lstm(embeds)\n","\n","        # Apply self-attention\n","        self_attention_out = self.self_attention(lstm_out)\n","\n","        # Apply Simple attention\n","        context_vector = self.simple_attention(self_attention_out)\n","\n","        context_vector = self.dropout(context_vector)\n","        context_vector = self.relu(self.fc1(context_vector))\n","        context_vector = self.dropout(context_vector)\n","        context_vector = torch.sigmoid(self.fc2(context_vector))\n","        return context_vector.squeeze()\n","\n","\n","# Instantiate the model\n","model = SentimentRNNWithSelfAttention(embedding_matrix)\n","\n","# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.5, verbose=True)\n","\n","# Training loop with validation and early stopping\n","num_epochs = 30\n","patience = 5  # Early stopping patience\n","best_val_accuracy = 0\n","epochs_no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for sequences, labels in train_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(sequences)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)  # Gradient clipping\n","        optimizer.step()\n","        running_loss += loss.item() * sequences.size(0)\n","    epoch_loss = running_loss / len(train_dataset)\n","\n","    # Validation\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for sequences, labels in val_loader:\n","            sequences = sequences.to(device)\n","            labels = labels.to(device)\n","            outputs = model(sequences)\n","            predicted = (outputs >= 0.5).long()\n","            correct += (predicted == labels.long()).sum().item()\n","            total += labels.size(0)\n","    val_accuracy = correct / total\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # Learning rate scheduling\n","    scheduler.step(val_accuracy)\n","\n","    # Check for improvement\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        epochs_no_improve = 0\n","        # Save the best model\n","        torch.save(model.state_dict(), 'best_model_self_attention.pt')\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print('Early stopping!')\n","            break"],"id":"k3rsRF-XMDh6"},{"cell_type":"code","source":["# Load the best model and evaluate on the test set\n","model = SentimentRNNWithSelfAttention(embedding_matrix)\n","model.load_state_dict(torch.load('best_model_self_attention.pt'))\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for sequences, labels in test_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        outputs = model(sequences)\n","        predicted = (outputs >= 0.5).long()\n","        correct += (predicted == labels.long()).sum().item()\n","        total += labels.size(0)\n","test_accuracy = correct / total\n","print(f'Accuracy Score on Test dataset: {test_accuracy:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LtZZa2mhsqEq","executionInfo":{"status":"ok","timestamp":1730903475984,"user_tz":-480,"elapsed":9432,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}},"outputId":"3f1a0f83-4d18-421a-e2a0-f2ae629fc654"},"id":"LtZZa2mhsqEq","execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-9618ebdeeea4>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load('best_model_self_attention.pt'))\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy Score on Test dataset: 0.7645\n"]}]},{"cell_type":"code","execution_count":null,"id":"d25d2ba3-a6df-4a02-905d-ca10c4b6f7c2","metadata":{"id":"d25d2ba3-a6df-4a02-905d-ca10c4b6f7c2"},"outputs":[],"source":["#3.1"]},{"cell_type":"markdown","source":["\n"],"metadata":{"id":"575bNvVEMAlm"},"id":"575bNvVEMAlm"},{"cell_type":"code","execution_count":null,"id":"648ea703-d9ac-4256-8862-a5d6231fbbd6","metadata":{"id":"648ea703-d9ac-4256-8862-a5d6231fbbd6"},"outputs":[],"source":["class SentimentRNN_UpdateEmbeddings(nn.Module):\n","    def __init__(self, embedding_matrix):\n","        super(SentimentRNN_UpdateEmbeddings, self).__init__()\n","        vocab_size, embedding_dim = embedding_matrix.shape\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.embedding.weight.data.copy_(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding.weight.requires_grad = True  # Update the embeddings during training\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size=256, batch_first=True, bidirectional=True, num_layers=2, dropout=0.5)\n","        self.fc1 = nn.Linear(512, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        embeds = self.embedding(x)\n","        lstm_out, (h_n, c_n) = self.lstm(embeds)\n","\n","        # Concatenate the final hidden states from both directions\n","        out = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n","\n","        out = self.dropout(out)\n","        out = self.relu(self.fc1(out))\n","        out = self.dropout(out)\n","        out = torch.sigmoid(self.fc2(out))\n","        return out.squeeze()"]},{"cell_type":"code","execution_count":null,"id":"7845f038-3527-47fb-aa91-18912dab8858","metadata":{"id":"7845f038-3527-47fb-aa91-18912dab8858","outputId":"75a5df9c-c570-4cd1-a7b9-40a2b4cb181e","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1730520564531,"user_tz":-480,"elapsed":84180,"user":{"displayName":"Shan Shan","userId":"00333815406818419816"}}},"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-41bf73be0b91>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Gradient clipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Instantiate the model\n","model = SentimentRNN_UpdateEmbeddings(embedding_matrix)\n","\n","# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.5, verbose=True)\n","\n","# Training loop with validation and early stopping\n","num_epochs = 30\n","patience = 5  # Early stopping patience\n","best_val_accuracy = 0\n","epochs_no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for sequences, labels in train_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(sequences)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)  # Gradient clipping\n","        optimizer.step()\n","        running_loss += loss.item() * sequences.size(0)\n","    epoch_loss = running_loss / len(train_dataset)\n","\n","    # Validation\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for sequences, labels in val_loader:\n","            sequences = sequences.to(device)\n","            labels = labels.to(device)\n","            outputs = model(sequences)\n","            predicted = (outputs >= 0.5).long()\n","            correct += (predicted == labels.long()).sum().item()\n","            total += labels.size(0)\n","    val_accuracy = correct / total\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # Learning rate scheduling\n","    scheduler.step(val_accuracy)\n","\n","    # Check for improvement\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        epochs_no_improve = 0\n","        # Save the best model\n","        torch.save(model.state_dict(), 'best_model_update_embeddings.pt')\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print('Early stopping!')\n","            break\n","\n","# Load the best model and evaluate on the test set\n","model.load_state_dict(torch.load('best_model_update_embeddings.pt'))\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for sequences, labels in test_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        outputs = model(sequences)\n","        predicted = (outputs >= 0.5).long()\n","        correct += (predicted == labels.long()).sum().item()\n","        total += labels.size(0)\n","test_accuracy = correct / total\n","print(f'Test Accuracy: {test_accuracy:.4f}')"]},{"cell_type":"code","execution_count":null,"id":"4f4871eb-ca38-4b34-aeb5-71f8681c099f","metadata":{"id":"4f4871eb-ca38-4b34-aeb5-71f8681c099f"},"outputs":[],"source":["#3.2"]},{"cell_type":"code","execution_count":null,"id":"f4a04cf4-0aa3-4466-bbb3-677bf4d75aed","metadata":{"id":"f4a04cf4-0aa3-4466-bbb3-677bf4d75aed"},"outputs":[],"source":["# Load the GloVe embeddings\n","glove_vocab = set()\n","with open('glove.6B.100d.txt', 'r', encoding='utf8') as f:\n","    for line in f:\n","        word = line.split()[0]\n","        glove_vocab.add(word)\n","\n","# Initialize the embedding matrix with random values\n","embedding_dim = 100\n","vocab_size = len(vocabulary)\n","embedding_matrix = np.random.uniform(-0.05, 0.05, (vocab_size, embedding_dim))\n","\n","# Create a dictionary to store the GloVe embeddings\n","glove_embeddings = {}\n","glove_file = 'glove.6B.100d.txt'\n","with open(glove_file, 'r', encoding='utf8') as f:\n","    for line in f:\n","        values = line.split()\n","        glove_word = values[0]\n","        vector = np.asarray(values[1:], dtype='float32')\n","        # Normalize the loaded vectors to have unit norm\n","        vector /= np.linalg.norm(vector)\n","        glove_embeddings[glove_word] = vector\n","\n","# Load GloVe embeddings into the embedding matrix where possible\n","for idx, word in enumerate(vocabulary):\n","    if word in glove_embeddings:\n","        embedding_matrix[idx] = glove_embeddings[word]"]},{"cell_type":"code","execution_count":null,"id":"6a2a4400-44f8-40a6-93f3-683c5dc8df9a","metadata":{"id":"6a2a4400-44f8-40a6-93f3-683c5dc8df9a"},"outputs":[],"source":["class SentimentRNN_OOV(nn.Module):\n","    def __init__(self, embedding_matrix):\n","        super(SentimentRNN_OOV, self).__init__()\n","        vocab_size, embedding_dim = embedding_matrix.shape\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.embedding.weight.data.copy_(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding.weight.requires_grad = True\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size=256, batch_first=True, bidirectional=True, num_layers=2, dropout=0.5)\n","        self.fc1 = nn.Linear(512, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        embeds = self.embedding(x)\n","        lstm_out, (h_n, c_n) = self.lstm(embeds)\n","\n","        # Concatenate the final hidden states from both directions\n","        out = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n","\n","        out = self.dropout(out)\n","        out = self.relu(self.fc1(out))\n","        out = self.dropout(out)\n","        out = torch.sigmoid(self.fc2(out))\n","        return out.squeeze()"]},{"cell_type":"code","execution_count":null,"id":"893eaca0-ee17-4434-a4c3-014ddcc1e452","metadata":{"id":"893eaca0-ee17-4434-a4c3-014ddcc1e452","outputId":"f491e627-396f-4ce4-9dd9-2a075636203f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/30], Loss: 0.6444, Validation Accuracy: 0.7514\n","Epoch [2/30], Loss: 0.4196, Validation Accuracy: 0.7552\n","Epoch [3/30], Loss: 0.2322, Validation Accuracy: 0.7495\n","Epoch [4/30], Loss: 0.1236, Validation Accuracy: 0.7542\n","Epoch [5/30], Loss: 0.0663, Validation Accuracy: 0.7392\n","Epoch [6/30], Loss: 0.0291, Validation Accuracy: 0.7458\n","Epoch [7/30], Loss: 0.0119, Validation Accuracy: 0.7477\n","Early stopping!\n"]}],"source":["\n","# Instantiate the model\n","model = SentimentRNN_OOV(embedding_matrix)\n","\n","# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2, factor=0.5, verbose=True)\n","\n","# Training loop with validation and early stopping\n","num_epochs = 30\n","patience = 5  # Early stopping patience\n","best_val_accuracy = 0\n","epochs_no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for sequences, labels in train_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(sequences)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)  # Gradient clipping\n","        optimizer.step()\n","        running_loss += loss.item() * sequences.size(0)\n","    epoch_loss = running_loss / len(train_dataset)\n","\n","    # Validation\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for sequences, labels in val_loader:\n","            sequences = sequences.to(device)\n","            labels = labels.to(device)\n","            outputs = model(sequences)\n","            predicted = (outputs >= 0.5).long()\n","            correct += (predicted == labels.long()).sum().item()\n","            total += labels.size(0)\n","    val_accuracy = correct / total\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # Learning rate scheduling\n","    scheduler.step(val_accuracy)\n","\n","    # Check for improvement\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        epochs_no_improve = 0\n","        # Save the best model\n","        torch.save(model.state_dict(), 'best_model_oov.pt')\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print('Early stopping!')\n","            break\n"]},{"cell_type":"code","execution_count":null,"id":"5cb26e55-c0b7-4341-accd-7693a04c12ed","metadata":{"id":"5cb26e55-c0b7-4341-accd-7693a04c12ed","outputId":"67628f37-0b67-43b7-bd22-29cea3a64bc7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Test Accuracy: 0.7720\n"]}],"source":["# Load the best model and evaluate on the test set\n","model.load_state_dict(torch.load('best_model_oov.pt'))\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for sequences, labels in test_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        outputs = model(sequences)\n","        predicted = (outputs >= 0.5).long()\n","        correct += (predicted == labels.long()).sum().item()\n","        total += labels.size(0)\n","test_accuracy = correct / total\n","print(f'Test Accuracy: {test_accuracy:.4f}')"]},{"cell_type":"code","execution_count":null,"id":"ec35fbe0-eaf1-446e-ae13-38be9a9d9619","metadata":{"id":"ec35fbe0-eaf1-446e-ae13-38be9a9d9619"},"outputs":[],"source":["# biLSTM Model\n","class SentimentBiLSTM(nn.Module):\n","    def __init__(self, embedding_matrix):\n","        super(SentimentBiLSTM, self).__init__()\n","        vocab_size, embedding_dim = embedding_matrix.shape\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.embedding.weight.data.copy_(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding.weight.requires_grad = True\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size=256, batch_first=True, bidirectional=True, num_layers=2, dropout=0.5)\n","        self.fc1 = nn.Linear(512, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        embeds = self.embedding(x)\n","        lstm_out, (h_n, c_n) = self.lstm(embeds)\n","\n","        # Concatenate the final hidden states from both directions\n","        out = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n","\n","        out = self.dropout(out)\n","        out = self.relu(self.fc1(out))\n","        out = self.dropout(out)\n","        out = torch.sigmoid(self.fc2(out))\n","        return out.squeeze()"]},{"cell_type":"code","execution_count":null,"id":"66822818-6b88-4c9a-a24b-d3e2521c7976","metadata":{"id":"66822818-6b88-4c9a-a24b-d3e2521c7976"},"outputs":[],"source":["# biLSTM Model\n","class SentimentBiLSTM(nn.Module):\n","    def __init__(self, embedding_matrix):\n","        super(SentimentBiLSTM, self).__init__()\n","        vocab_size, embedding_dim = embedding_matrix.shape\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.embedding.weight.data.copy_(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding.weight.requires_grad = True\n","        self.lstm = nn.LSTM(embedding_dim, hidden_size=256, batch_first=True, bidirectional=True, num_layers=2, dropout=0.5)\n","        self.fc1 = nn.Linear(512, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        embeds = self.embedding(x)\n","        lstm_out, (h_n, c_n) = self.lstm(embeds)\n","\n","        # Concatenate the final hidden states from both directions\n","        out = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n","\n","        out = self.dropout(out)\n","        out = self.relu(self.fc1(out))\n","        out = self.dropout(out)\n","        out = torch.sigmoid(self.fc2(out))\n","        return out.squeeze()\n","\n","\n","# biGRU Model\n","class SentimentBiGRU(nn.Module):\n","    def __init__(self, embedding_matrix):\n","        super(SentimentBiGRU, self).__init__()\n","        vocab_size, embedding_dim = embedding_matrix.shape\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.embedding.weight.data.copy_(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding.weight.requires_grad = True\n","        self.gru = nn.GRU(embedding_dim, hidden_size=256, batch_first=True, bidirectional=True, num_layers=2, dropout=0.5)\n","        self.fc1 = nn.Linear(512, 128)\n","        self.fc2 = nn.Linear(128, 1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        embeds = self.embedding(x)\n","        gru_out, h_n = self.gru(embeds)\n","\n","        # Concatenate the final hidden states from both directions\n","        out = torch.cat((h_n[-2,:,:], h_n[-1,:,:]), dim=1)\n","\n","        out = self.dropout(out)\n","        out = self.relu(self.fc1(out))\n","        out = self.dropout(out)\n","        out = torch.sigmoid(self.fc2(out))\n","        return out.squeeze()\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"8b85e41b-0b7c-4a92-a2e4-35b26a260753","metadata":{"id":"8b85e41b-0b7c-4a92-a2e4-35b26a260753"},"outputs":[],"source":["# Instantiate the models\n","bilstm_model = SentimentBiLSTM(embedding_matrix)\n","bigru_model = SentimentBiGRU(embedding_matrix)\n","\n","# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","bilstm_model.to(device)\n","bigru_model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.BCELoss()\n","bilstm_optimizer = torch.optim.Adam(bilstm_model.parameters(), lr=0.001, weight_decay=1e-5)\n","bigru_optimizer = torch.optim.Adam(bigru_model.parameters(), lr=0.001, weight_decay=1e-5)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(bilstm_optimizer, 'max', patience=2, factor=0.5, verbose=True)"]},{"cell_type":"code","execution_count":null,"id":"97491727-7b18-4358-8347-f5948c55e741","metadata":{"id":"97491727-7b18-4358-8347-f5948c55e741","outputId":"9c24b704-dec7-42d8-9b2c-dbad2c8533ac"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/30], Loss: 0.6494, Validation Accuracy: 0.7345\n","Epoch [2/30], Loss: 0.4284, Validation Accuracy: 0.7523\n","Epoch [3/30], Loss: 0.2194, Validation Accuracy: 0.7411\n","Epoch [4/30], Loss: 0.1183, Validation Accuracy: 0.7570\n","Epoch [5/30], Loss: 0.0712, Validation Accuracy: 0.7683\n","Epoch [6/30], Loss: 0.0434, Validation Accuracy: 0.7439\n","Epoch [7/30], Loss: 0.0275, Validation Accuracy: 0.7580\n","Epoch [8/30], Loss: 0.0184, Validation Accuracy: 0.7561\n","Epoch [9/30], Loss: 0.0102, Validation Accuracy: 0.7561\n","Epoch [10/30], Loss: 0.0059, Validation Accuracy: 0.7552\n","Early stopping!\n","biLSTM Test Accuracy: 0.7795\n"]}],"source":["# Training loop with validation and early stopping for biLSTM\n","num_epochs = 30\n","patience = 5  # Early stopping patience\n","best_val_accuracy = 0\n","epochs_no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    bilstm_model.train()\n","    running_loss = 0.0\n","    for sequences, labels in train_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        bilstm_optimizer.zero_grad()\n","        outputs = bilstm_model(sequences)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(bilstm_model.parameters(), max_norm=1)  # Gradient clipping\n","        bilstm_optimizer.step()\n","        running_loss += loss.item() * sequences.size(0)\n","    epoch_loss = running_loss / len(train_dataset)\n","\n","    # Validation\n","    bilstm_model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for sequences, labels in val_loader:\n","            sequences = sequences.to(device)\n","            labels = labels.to(device)\n","            outputs = bilstm_model(sequences)\n","            predicted = (outputs >= 0.5).long()\n","            correct += (predicted == labels.long()).sum().item()\n","            total += labels.size(0)\n","    val_accuracy = correct / total\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # Learning rate scheduling\n","    scheduler.step(val_accuracy)\n","\n","    # Check for improvement\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        epochs_no_improve = 0\n","        # Save the best model\n","        torch.save(bilstm_model.state_dict(), 'best_bilstm_model.pt')\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print('Early stopping!')\n","            break\n","\n","# Load the best model and evaluate on the test set for biLSTM\n","bilstm_model.load_state_dict(torch.load('best_bilstm_model.pt'))\n","bilstm_model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for sequences, labels in test_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        outputs = bilstm_model(sequences)\n","        predicted = (outputs >= 0.5).long()\n","        correct += (predicted == labels.long()).sum().item()\n","        total += labels.size(0)\n","bilstm_test_accuracy = correct / total\n","print(f'biLSTM Test Accuracy: {bilstm_test_accuracy:.4f}')"]},{"cell_type":"code","execution_count":null,"id":"66d3c019-9c12-4dd9-9346-d66f1f9831a0","metadata":{"id":"66d3c019-9c12-4dd9-9346-d66f1f9831a0","outputId":"0f69aa72-897f-41b5-90cb-bd3d7929dc0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch [1/30], Loss: 0.6209, Validation Accuracy: 0.7176\n","Epoch [2/30], Loss: 0.3693, Validation Accuracy: 0.7523\n","Epoch [3/30], Loss: 0.1926, Validation Accuracy: 0.7580\n","Epoch [4/30], Loss: 0.0981, Validation Accuracy: 0.7486\n","Epoch [5/30], Loss: 0.0543, Validation Accuracy: 0.7439\n","Epoch [6/30], Loss: 0.0264, Validation Accuracy: 0.7289\n","Epoch [7/30], Loss: 0.0156, Validation Accuracy: 0.7355\n","Epoch [8/30], Loss: 0.0113, Validation Accuracy: 0.7383\n","Early stopping!\n","biGRU Test Accuracy: 0.7795\n"]}],"source":["# Training loop with validation and early stopping for biGRU\n","num_epochs = 30\n","patience = 5  # Early stopping patience\n","best_val_accuracy = 0\n","epochs_no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    bigru_model.train()\n","    running_loss = 0.0\n","    for sequences, labels in train_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        bigru_optimizer.zero_grad()\n","        outputs = bigru_model(sequences)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(bigru_model.parameters(), max_norm=1)  # Gradient clipping\n","        bigru_optimizer.step()\n","        running_loss += loss.item() * sequences.size(0)\n","    epoch_loss = running_loss / len(train_dataset)\n","\n","    # Validation\n","    bigru_model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for sequences, labels in val_loader:\n","            sequences = sequences.to(device)\n","            labels = labels.to(device)\n","            outputs = bigru_model(sequences)\n","            predicted = (outputs >= 0.5).long()\n","            correct += (predicted == labels.long()).sum().item()\n","            total += labels.size(0)\n","    val_accuracy = correct / total\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # Learning rate scheduling\n","    scheduler.step(val_accuracy)\n","\n","    # Check for improvement\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        epochs_no_improve = 0\n","        # Save the best model\n","        torch.save(bigru_model.state_dict(), 'best_bigru_model.pt')\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print('Early stopping!')\n","            break\n","\n","# Load the best model and evaluate on the test set for biGRU\n","bigru_model.load_state_dict(torch.load('best_bigru_model.pt'))\n","bigru_model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for sequences, labels in test_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        outputs = bigru_model(sequences)\n","        predicted = (outputs >= 0.5).long()\n","        correct += (predicted == labels.long()).sum().item()\n","        total += labels.size(0)\n","bigru_test_accuracy = correct / total\n","print(f'biGRU Test Accuracy: {bigru_test_accuracy:.4f}')"]},{"cell_type":"code","execution_count":null,"id":"4f1f661d-d038-44ce-a688-c19a6db7b74f","metadata":{"id":"4f1f661d-d038-44ce-a688-c19a6db7b74f"},"outputs":[],"source":["# CNN Model\n","class SentimentCNN(nn.Module):\n","    def __init__(self, embedding_matrix):\n","        super(SentimentCNN, self).__init__()\n","        vocab_size, embedding_dim = embedding_matrix.shape\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.embedding.weight.data.copy_(torch.tensor(embedding_matrix, dtype=torch.float32))\n","        self.embedding.weight.requires_grad = True\n","        self.conv1 = nn.Conv1d(embedding_dim, 128, kernel_size=3, padding=1)\n","        self.dropout = nn.Dropout(0.5)\n","        self.fc1 = nn.Linear(128, 64)\n","        self.fc2 = nn.Linear(64, 1)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        embeds = self.embedding(x).permute(0, 2, 1)\n","        conv_out = self.conv1(embeds)\n","        pool_out = torch.max(conv_out, dim=-1)[0]\n","        out = self.dropout(pool_out)\n","        out = self.relu(self.fc1(out))\n","        out = self.dropout(out)\n","        out = torch.sigmoid(self.fc2(out))\n","        return out.squeeze()"]},{"cell_type":"code","execution_count":null,"id":"4559d670-cf2a-44e9-9c02-25d46f388241","metadata":{"id":"4559d670-cf2a-44e9-9c02-25d46f388241","outputId":"7072f1fa-278b-40f8-a599-828d8843427f"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Samuel Ng\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n","  return F.conv1d(input, weight, bias, self.stride,\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/30], Loss: 0.6628, Validation Accuracy: 0.7270\n","Epoch [2/30], Loss: 0.4245, Validation Accuracy: 0.7645\n","Epoch [3/30], Loss: 0.1890, Validation Accuracy: 0.7711\n","Epoch [4/30], Loss: 0.0689, Validation Accuracy: 0.7608\n","Epoch [5/30], Loss: 0.0259, Validation Accuracy: 0.7467\n","Epoch [6/30], Loss: 0.0147, Validation Accuracy: 0.7448\n","Epoch [7/30], Loss: 0.0059, Validation Accuracy: 0.7477\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Samuel Ng\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n","  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [8/30], Loss: 0.0047, Validation Accuracy: 0.7523\n","Early stopping!\n","CNN Test Accuracy: 0.7805\n"]}],"source":["# Instantiate the model\n","cnn_model = SentimentCNN(embedding_matrix)\n","\n","# Set device to GPU if available\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","cnn_model.to(device)\n","\n","# Define loss function and optimizer\n","criterion = nn.BCELoss()\n","cnn_optimizer = torch.optim.Adam(cnn_model.parameters(), lr=0.001, weight_decay=1e-5)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(cnn_optimizer, 'max', patience=2, factor=0.5, verbose=True)\n","\n","# Training loop with validation and early stopping\n","num_epochs = 30\n","patience = 5  # Early stopping patience\n","best_val_accuracy = 0\n","epochs_no_improve = 0\n","\n","for epoch in range(num_epochs):\n","    cnn_model.train()\n","    running_loss = 0.0\n","    for sequences, labels in train_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        cnn_optimizer.zero_grad()\n","        outputs = cnn_model(sequences)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(cnn_model.parameters(), max_norm=1)  # Gradient clipping\n","        cnn_optimizer.step()\n","        running_loss += loss.item() * sequences.size(0)\n","    epoch_loss = running_loss / len(train_dataset)\n","\n","    # Validation\n","    cnn_model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for sequences, labels in val_loader:\n","            sequences = sequences.to(device)\n","            labels = labels.to(device)\n","            outputs = cnn_model(sequences)\n","            predicted = (outputs >= 0.5).long()\n","            correct += (predicted == labels.long()).sum().item()\n","            total += labels.size(0)\n","    val_accuracy = correct / total\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n","\n","    # Learning rate scheduling\n","    scheduler.step(val_accuracy)\n","\n","    # Check for improvement\n","    if val_accuracy > best_val_accuracy:\n","        best_val_accuracy = val_accuracy\n","        epochs_no_improve = 0\n","        # Save the best model\n","        torch.save(cnn_model.state_dict(), 'best_cnn_model.pt')\n","    else:\n","        epochs_no_improve += 1\n","        if epochs_no_improve >= patience:\n","            print('Early stopping!')\n","            break\n","\n","# Load the best model and evaluate on the test set\n","cnn_model.load_state_dict(torch.load('best_cnn_model.pt'))\n","cnn_model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for sequences, labels in test_loader:\n","        sequences = sequences.to(device)\n","        labels = labels.to(device)\n","        outputs = cnn_model(sequences)\n","        predicted = (outputs >= 0.5).long()\n","        correct += (predicted == labels.long()).sum().item()\n","        total += labels.size(0)\n","cnn_test_accuracy = correct / total\n","print(f'CNN Test Accuracy: {cnn_test_accuracy:.4f}')"]},{"cell_type":"code","execution_count":null,"id":"9f013a0d-b7d8-4c73-bd66-d6e9cdbaf080","metadata":{"id":"9f013a0d-b7d8-4c73-bd66-d6e9cdbaf080"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"1eaeafc739b7429885bc067a1338f93b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d459ef8602ca45259d414c800b1555dd","IPY_MODEL_9d3dd33a67ca45a9992501ba088c5f2c","IPY_MODEL_83bf335d998e403d9416bb000eecb08d"],"layout":"IPY_MODEL_97af5cde7c034fe1b976e709c9d77415"}},"d459ef8602ca45259d414c800b1555dd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_233d0f97b7cb466f85d7da7236d23e3c","placeholder":"​","style":"IPY_MODEL_8bf28eaafe9b4ec6ba24096dad298460","value":"README.md: 100%"}},"9d3dd33a67ca45a9992501ba088c5f2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a5f045f9150a44a88ef41bacb39b7022","max":7457,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03741984e10d458599849597a5c6c713","value":7457}},"83bf335d998e403d9416bb000eecb08d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9acadcd18490400dbbb8cee530f81131","placeholder":"​","style":"IPY_MODEL_e72fe962d53546619c6d5499dbd260a2","value":" 7.46k/7.46k [00:00&lt;00:00, 133kB/s]"}},"97af5cde7c034fe1b976e709c9d77415":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"233d0f97b7cb466f85d7da7236d23e3c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bf28eaafe9b4ec6ba24096dad298460":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5f045f9150a44a88ef41bacb39b7022":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03741984e10d458599849597a5c6c713":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9acadcd18490400dbbb8cee530f81131":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e72fe962d53546619c6d5499dbd260a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e094a560a3f4f5aa9d51d14d2de60de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3fe110ea8bae433b95a74281aa80058a","IPY_MODEL_db19ec725a70457c8fc81f92f54ab549","IPY_MODEL_9c7e712053794112ace3cc5033ab7e22"],"layout":"IPY_MODEL_f48c5a035ec64ff98e77561c783f6982"}},"3fe110ea8bae433b95a74281aa80058a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d545a628e3d4834878dc719f547d666","placeholder":"​","style":"IPY_MODEL_bcfcaeba5cb040ccb655d93935b21542","value":"train.parquet: 100%"}},"db19ec725a70457c8fc81f92f54ab549":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e79ae022570443ea97fcf4fdf9a69ae9","max":698845,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7917a1a3bf53496d9f2862162ef1c511","value":698845}},"9c7e712053794112ace3cc5033ab7e22":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d6ac49983264c00a59a71e84aaee965","placeholder":"​","style":"IPY_MODEL_e4296c8b138f4b6e94f04787d39cc42d","value":" 699k/699k [00:00&lt;00:00, 5.23MB/s]"}},"f48c5a035ec64ff98e77561c783f6982":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d545a628e3d4834878dc719f547d666":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcfcaeba5cb040ccb655d93935b21542":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e79ae022570443ea97fcf4fdf9a69ae9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7917a1a3bf53496d9f2862162ef1c511":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2d6ac49983264c00a59a71e84aaee965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4296c8b138f4b6e94f04787d39cc42d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d43cbc3e48c54a288c15f984fabc1295":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09aa48a3099f4cdf88ac47fabb34b8e0","IPY_MODEL_2a749993df8f462091b9fd000c9049ce","IPY_MODEL_8e8665f721f747b2917063383d47e6d2"],"layout":"IPY_MODEL_507204dca10f40efaeb9802cc528164f"}},"09aa48a3099f4cdf88ac47fabb34b8e0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95cd4944dce04ea993ffa5a7aa9d9a77","placeholder":"​","style":"IPY_MODEL_872589abab474180b267b247e498ef6c","value":"validation.parquet: 100%"}},"2a749993df8f462091b9fd000c9049ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_96a4d35b79d04146be9f8f702b6e65c4","max":90001,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0064eeebb72a45408027b4989764d47d","value":90001}},"8e8665f721f747b2917063383d47e6d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94c74f7de1c84b918b0b5c8fed7cb78f","placeholder":"​","style":"IPY_MODEL_a3d55ae533774c20a63fc3c0f9849d5a","value":" 90.0k/90.0k [00:00&lt;00:00, 5.09MB/s]"}},"507204dca10f40efaeb9802cc528164f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95cd4944dce04ea993ffa5a7aa9d9a77":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"872589abab474180b267b247e498ef6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"96a4d35b79d04146be9f8f702b6e65c4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0064eeebb72a45408027b4989764d47d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94c74f7de1c84b918b0b5c8fed7cb78f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3d55ae533774c20a63fc3c0f9849d5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce3d6b84fd3244ec8b4dc3b0f4377b42":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95fffec6311c41dbbc806b114d39f3d8","IPY_MODEL_ddcb0987684b43ca91d0b0ebb1195a4c","IPY_MODEL_fb91f09d1dd547018840305cce8584e2"],"layout":"IPY_MODEL_58b9161328334eed8042e683836f268b"}},"95fffec6311c41dbbc806b114d39f3d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a23d18936ea04674988d9a594a9793fb","placeholder":"​","style":"IPY_MODEL_6a350b91b09f400a91d8f0d8406440d1","value":"test.parquet: 100%"}},"ddcb0987684b43ca91d0b0ebb1195a4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_66d31298737b45a8856e8d2194d3b017","max":92206,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fbc36cbc4e74637b6b9f936906174d5","value":92206}},"fb91f09d1dd547018840305cce8584e2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8498a5e31138441ba348e9a8b2357bf7","placeholder":"​","style":"IPY_MODEL_f71e78769e0c413fb867f2306684d59a","value":" 92.2k/92.2k [00:00&lt;00:00, 3.20MB/s]"}},"58b9161328334eed8042e683836f268b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a23d18936ea04674988d9a594a9793fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6a350b91b09f400a91d8f0d8406440d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"66d31298737b45a8856e8d2194d3b017":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fbc36cbc4e74637b6b9f936906174d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8498a5e31138441ba348e9a8b2357bf7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f71e78769e0c413fb867f2306684d59a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a8c37a79a1043168031b89b9d611885":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ad697d17c78491682ecab0d549e1c5f","IPY_MODEL_887e8addc0f24123972169a728fe4a01","IPY_MODEL_830699661bce4d378b9b68e758031c6e"],"layout":"IPY_MODEL_ba28137209384d249a5ad65ece0c4fc7"}},"4ad697d17c78491682ecab0d549e1c5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a057581b593c4fff959ed6ba0a3deb61","placeholder":"​","style":"IPY_MODEL_9ec75cba7f5c4eeca23f05ff1e5a7924","value":"Generating train split: 100%"}},"887e8addc0f24123972169a728fe4a01":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fe7a008d71dd4936b1d5488d1ba6c32f","max":8530,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78d5eb3bfb534f3f9258c15fcba80065","value":8530}},"830699661bce4d378b9b68e758031c6e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0616160454fd4fa9ac1425b4b6c4dddd","placeholder":"​","style":"IPY_MODEL_9b887a6f1b6046cf8efa6cdf4ab5b69c","value":" 8530/8530 [00:00&lt;00:00, 90926.78 examples/s]"}},"ba28137209384d249a5ad65ece0c4fc7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a057581b593c4fff959ed6ba0a3deb61":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ec75cba7f5c4eeca23f05ff1e5a7924":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe7a008d71dd4936b1d5488d1ba6c32f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78d5eb3bfb534f3f9258c15fcba80065":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0616160454fd4fa9ac1425b4b6c4dddd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b887a6f1b6046cf8efa6cdf4ab5b69c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"719942d754a941faa7084206457746ce":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_676d434e8b4646e295aec532c5ec5afa","IPY_MODEL_e6a35a17cea142419e1355f3fd396f3a","IPY_MODEL_9070cc2b799547aab8a164a1ee46c610"],"layout":"IPY_MODEL_993153cf320c41dda456162f7082d65d"}},"676d434e8b4646e295aec532c5ec5afa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ea7bd52d2c346bcbe8bdb3069cd6549","placeholder":"​","style":"IPY_MODEL_1d5ac23553b0460b931a8f8f38eaf279","value":"Generating validation split: 100%"}},"e6a35a17cea142419e1355f3fd396f3a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_84cc52be0a4448d6a81fd7c658a7e07c","max":1066,"min":0,"orientation":"horizontal","style":"IPY_MODEL_403ca25848674f51b057c80b27d19cdb","value":1066}},"9070cc2b799547aab8a164a1ee46c610":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d946086111f24172b5b39ba2429f12e3","placeholder":"​","style":"IPY_MODEL_f528d805680d43fb84c3b69c413495b0","value":" 1066/1066 [00:00&lt;00:00, 25023.52 examples/s]"}},"993153cf320c41dda456162f7082d65d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ea7bd52d2c346bcbe8bdb3069cd6549":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d5ac23553b0460b931a8f8f38eaf279":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84cc52be0a4448d6a81fd7c658a7e07c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"403ca25848674f51b057c80b27d19cdb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d946086111f24172b5b39ba2429f12e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f528d805680d43fb84c3b69c413495b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"788e221ffa644efe81418aec13c3e2b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_362a6994dad74285a66fd27715b87eed","IPY_MODEL_55c2791b76584f7c958b4eef0e6311ac","IPY_MODEL_01cade4a2c5c4443a9c258d6c56c6902"],"layout":"IPY_MODEL_bf5be7fdaa75481691c14f81b64360d3"}},"362a6994dad74285a66fd27715b87eed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_089155ac8f244c6fb099531e72725446","placeholder":"​","style":"IPY_MODEL_337fb731ff2649058504d1ed3d28b948","value":"Generating test split: 100%"}},"55c2791b76584f7c958b4eef0e6311ac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67de08048f8540f0aece6fb0f4909927","max":1066,"min":0,"orientation":"horizontal","style":"IPY_MODEL_aa7bc58b61584cc691a4391ab5bd0bc3","value":1066}},"01cade4a2c5c4443a9c258d6c56c6902":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a9296c6303f4bf5a474c459569f7acb","placeholder":"​","style":"IPY_MODEL_b2b210a445714b8793e4657d7463ef7a","value":" 1066/1066 [00:00&lt;00:00, 27647.51 examples/s]"}},"bf5be7fdaa75481691c14f81b64360d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"089155ac8f244c6fb099531e72725446":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"337fb731ff2649058504d1ed3d28b948":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67de08048f8540f0aece6fb0f4909927":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aa7bc58b61584cc691a4391ab5bd0bc3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5a9296c6303f4bf5a474c459569f7acb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2b210a445714b8793e4657d7463ef7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}